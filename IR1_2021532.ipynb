{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtJlfAjgMS5LJeWjNjM/Yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Q1. Data Preprocessing"],"metadata":{"id":"8ALIj107Mo2w"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UnZNPgKMZxM","executionInfo":{"status":"ok","timestamp":1707388974000,"user_tz":-330,"elapsed":27676,"user":{"displayName":"Ishwar Babu","userId":"14806234187012801256"}},"outputId":"6105dad1-093c-42c6-ac77-2b6709b33eb8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJQuyeztSNom","executionInfo":{"status":"ok","timestamp":1707389026760,"user_tz":-330,"elapsed":1223,"user":{"displayName":"Ishwar Babu","userId":"14806234187012801256"}},"outputId":"6caef139-ab86-46df-b833-c0c1d653811f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s51alAlRJPaD","executionInfo":{"status":"ok","timestamp":1707389063910,"user_tz":-330,"elapsed":34422,"user":{"displayName":"Ishwar Babu","userId":"14806234187012801256"}},"outputId":"b1bdfc15-6c18-4a7f-fd25-be0c9d367306"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3025ac412035>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, 'html.parser')\n"]},{"output_type":"stream","name":"stdout","text":["\n","Sample file: preprocessed_file161.txt\n","\n","\n","After Preprocessing:\n","\n","works guitar looks like new one\n","\n","Sample file: preprocessed_file390.txt\n","\n","\n","After Preprocessing:\n","\n","xvive sweet leo o2 lead distortion pedal demo im great lead player even able dial great tones pedal xvive sweet leo o2 distortion pedal great budget lead lead pedal im super impressed build quality packaging xvive well tones looking good lead distortion pedal functions like tube amp works may want c\n","\n","Sample file: preprocessed_file902.txt\n","\n","\n","After Preprocessing:\n","\n","beautiful strap matches guitar nicely perfect\n","\n","Sample file: preprocessed_file927.txt\n","\n","\n","After Preprocessing:\n","\n","ebay buy flip bad bass guitar worth much used new bridge pickup noisy pickups active pickup active pickup without boom sound would say 4 star everything gsr200 far body neck bridge mine 79 buy new 119 flip ok bass guitar string change setup first time bass buyer learning play\n","\n","Sample file: preprocessed_file678.txt\n","\n","\n","After Preprocessing:\n","\n","mixer good build knobs sliders smooth buttons click crackling quite hiss unless turn wide open big fan rca jacks portable best pick compared battery powered mixers imo mixer pedalboard pics used rca right angle adapters would fit pedalboard case\n"]}],"source":["import os\n","import random\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","def preprocess_text(text):\n","\n","    text = text.lower()\n","\n","    #Remove HTML tags using BeautifulSoup\n","    soup = BeautifulSoup(text, 'html.parser')\n","    text = soup.get_text()\n","\n","    #Tokenization\n","    tokens = word_tokenize(text)\n","\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word.lower() not in stop_words]\n","\n","\n","    tokens = [word for word in tokens if word.isalnum()]\n","\n","    #Remove blank space tokens\n","    tokens = [word for word in tokens if word.strip()]\n","\n","    return ' '.join(tokens)\n","\n","def preprocess_and_save_files(dataset_path, preprocessed_path):\n","    files = os.listdir(dataset_path)\n","    for file_name in files:\n","        file_path = os.path.join(dataset_path, file_name)\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            original_text = file.read()\n","            preprocessed_text = preprocess_text(original_text)\n","\n","        preprocessed_file_path = os.path.join(preprocessed_path, f\"preprocessed_{file_name}\")\n","        with open(preprocessed_file_path, 'w', encoding='utf-8') as preprocessed_file:\n","            preprocessed_file.write(preprocessed_text)\n","\n","def print_random_sample_files(preprocessed_path, num_samples=5):\n","    files = os.listdir(preprocessed_path)\n","    sample_files = random.sample(files, num_samples)\n","\n","    for file_name in sample_files:\n","        file_path = os.path.join(preprocessed_path, file_name)\n","\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            preprocessed_text = file.read()\n","            print(f\"\\nSample file: {file_name}\\n\")\n","            print(\"\\nAfter Preprocessing:\\n\")\n","            print(preprocessed_text[:300])  #Printing the first 300 characters\n","\n","if __name__ == \"__main__\":\n","    dataset_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/text_files\"\n","    preprocessed_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/Preprocessed_files\"\n","\n","\n","    if not os.path.exists(preprocessed_path):\n","        os.makedirs(preprocessed_path)\n","\n","\n","    preprocess_and_save_files(dataset_path, preprocessed_path)\n","\n","\n","    print_random_sample_files(preprocessed_path)\n"]},{"cell_type":"markdown","source":["Q2. Unigram Inverted Index and Boolean Queries\n"],"metadata":{"id":"Hev30RlWSb1F"}},{"cell_type":"code","source":["import os\n","import pickle\n","from collections import defaultdict\n","\n","def create_inverted_index(preprocessed_path):\n","    inverted_index = defaultdict(set)\n","    for file_name in os.listdir(preprocessed_path):\n","        file_path = os.path.join(preprocessed_path, file_name)\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            words = file.read().split()\n","            for word in words:\n","                inverted_index[word].add(file_name)\n","    return inverted_index\n","\n","def save_inverted_index(inverted_index, file_name):\n","    with open(file_name, 'wb') as file:\n","        pickle.dump(inverted_index, file)\n","\n","def load_inverted_index(file_name):\n","    with open(file_name, 'rb') as file:\n","        return pickle.load(file)\n","\n","def perform_query(inverted_index, query_terms, operations):\n","    result_sets = [inverted_index.get(term, set()) for term in query_terms]\n","\n","    result = result_sets[0]\n","    for op, next_set in zip(operations, result_sets[1:]):\n","        if op == 'AND':\n","            result = result & next_set\n","        elif op == 'OR':\n","            result = result | next_set\n","        elif op == 'AND NOT':\n","            result = result - next_set\n","        elif op == 'OR NOT':\n","            result = (result | next_set) - next_set\n","    return result\n","\n","def format_query(query_terms, operations):\n","    formatted_query = []\n","    for term, op in zip(query_terms, operations + ['']):\n","        formatted_query.append(term)\n","        if op:\n","            formatted_query.append(op)\n","    return ' '.join(formatted_query)\n","\n","def process_queries(preprocessed_path, inverted_index_file):\n","    inverted_index = load_inverted_index(inverted_index_file)\n","    n = int(input(\"Enter the number of queries: \"))\n","    queries = []\n","    for i in range(n):\n","        query_text = input(f\"Enter query {i + 1}: \")\n","        operations = input(f\"Enter operations for query {i + 1}, separated by commas: \").split(', ')\n","        queries.append((query_text, operations))\n","\n","    for i, (query_text, operations) in enumerate(queries):\n","        preprocessed_query = preprocess_text(query_text)\n","        query_terms = preprocessed_query.split()\n","\n","        result_docs = perform_query(inverted_index, query_terms, operations)\n","        formatted_query = format_query(query_terms, operations)\n","        print(f\"\\nQuery {i + 1}: {formatted_query}\")\n","        print(f\"Number of documents retrieved for query {i + 1}: {len(result_docs)}\")\n","        print(f\"Names of the documents retrieved for query {i + 1}: {', '.join(result_docs)}\")\n","\n","if __name__ == \"__main__\":\n","    dataset_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/text_files\"\n","    preprocessed_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/Preprocessed_files\"\n","    inverted_index_file = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/inverted_index.pkl\"\n","\n","    preprocess_and_save_files(dataset_path, preprocessed_path)\n","\n","    inverted_index = create_inverted_index(preprocessed_path)\n","    save_inverted_index(inverted_index, inverted_index_file)\n","\n","    process_queries(preprocessed_path, inverted_index_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NqB1gtVSmqj","executionInfo":{"status":"ok","timestamp":1707389174392,"user_tz":-330,"elapsed":84280,"user":{"displayName":"Ishwar Babu","userId":"14806234187012801256"}},"outputId":"fdd55971-f373-4f72-b104-61863baa4928"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3025ac412035>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, 'html.parser')\n"]},{"output_type":"stream","name":"stdout","text":["Enter the number of queries: 2\n","Enter query 1: Car bag in a canister\n","Enter operations for query 1, separated by commas: OR, AND NOT\n","Enter query 2: Coffee brewing techniques in cookbook\n","Enter operations for query 2, separated by commas: AND, OR NOT, OR\n","\n","Query 1: car OR bag AND NOT canister\n","Number of documents retrieved for query 1: 31\n","Names of the documents retrieved for query 1: preprocessed_file682.txt, preprocessed_file686.txt, preprocessed_file118.txt, preprocessed_file698.txt, preprocessed_file166.txt, preprocessed_file313.txt, preprocessed_file363.txt, preprocessed_file3.txt, preprocessed_file404.txt, preprocessed_file542.txt, preprocessed_file956.txt, preprocessed_file780.txt, preprocessed_file942.txt, preprocessed_file864.txt, preprocessed_file930.txt, preprocessed_file860.txt, preprocessed_file174.txt, preprocessed_file264.txt, preprocessed_file573.txt, preprocessed_file886.txt, preprocessed_file797.txt, preprocessed_file466.txt, preprocessed_file665.txt, preprocessed_file892.txt, preprocessed_file746.txt, preprocessed_file738.txt, preprocessed_file699.txt, preprocessed_file863.txt, preprocessed_file981.txt, preprocessed_file73.txt, preprocessed_file459.txt\n","\n","Query 2: coffee AND brewing OR NOT techniques OR cookbook\n","Number of documents retrieved for query 2: 0\n","Names of the documents retrieved for query 2: \n"]}]},{"cell_type":"markdown","source":["Q3. Positional Index and Phrase Queries"],"metadata":{"id":"q0ftNjKYVtmu"}},{"cell_type":"code","source":["import os\n","import pickle\n","from collections import defaultdict\n","\n","\n","def default_dict():\n","    return defaultdict(list)\n","\n","def create_positional_index(preprocessed_path):\n","    positional_index = defaultdict(default_dict)\n","    for file_name in os.listdir(preprocessed_path):\n","        file_path = os.path.join(preprocessed_path, file_name)\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            words = file.read().split()\n","            for position, word in enumerate(words):\n","                positional_index[word][file_name].append(position)\n","    return positional_index\n","\n","\n","def save_positional_index(positional_index, file_name):\n","    with open(file_name, 'wb') as file:\n","        pickle.dump(positional_index, file)\n","\n","def load_positional_index(file_name):\n","    with open(file_name, 'rb') as file:\n","        return pickle.load(file)\n","\n","def perform_phrase_query(positional_index, query_terms):\n","    if not query_terms:\n","        return set()\n","\n","    # Retrieving positional lists for each term in the phrase query\n","    positional_lists = [positional_index[term] for term in query_terms]\n","    all_docs = set.intersection(*map(set, positional_lists))\n","\n","    valid_docs = set()\n","    for doc in all_docs:\n","        positions = [positional_lists[i][doc] for i in range(len(query_terms))]\n","        for pos in positions[0]:\n","            if all(pos + i in positions[i] for i in range(len(query_terms))):\n","                valid_docs.add(doc)\n","                break\n","\n","    return valid_docs\n","\n","def process_queries(preprocessed_path, positional_index_file):\n","    positional_index = load_positional_index(positional_index_file)\n","    n = int(input(\"Enter the number of queries: \"))\n","    for i in range(n):\n","        query_text = input(f\"Enter phrase query {i + 1}: \")\n","        preprocessed_query = preprocess_text(query_text)\n","        query_terms = preprocessed_query.split()\n","\n","        result_docs = perform_phrase_query(positional_index, query_terms)\n","        print(f\"Number of documents retrieved for query {i + 1} using positional index: {len(result_docs)}\")\n","        print(f\"Names of documents retrieved for query {i + 1} using positional index: {', '.join(result_docs)}\")\n","\n","if __name__ == \"__main__\":\n","    dataset_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/text_files\"\n","    preprocessed_path = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/Preprocessed_files\"\n","    positional_index_file = \"/content/drive/My Drive/CSE508_Winter2024_A1_2021532/positional_index.pkl\"\n","\n","    preprocess_and_save_files(dataset_path, preprocessed_path)\n","\n","    positional_index = create_positional_index(preprocessed_path)\n","    save_positional_index(positional_index, positional_index_file)\n","\n","    process_queries(preprocessed_path, positional_index_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rgi4BRAQVv_f","executionInfo":{"status":"ok","timestamp":1707389312068,"user_tz":-330,"elapsed":105627,"user":{"displayName":"Ishwar Babu","userId":"14806234187012801256"}},"outputId":"212671e7-3f99-45c8-f3b1-7c15ede2f7e0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3025ac412035>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, 'html.parser')\n"]},{"output_type":"stream","name":"stdout","text":["Enter the number of queries: 3\n","Enter phrase query 1: it is a good in front for poutch\n","Number of documents retrieved for query 1 using positional index: 0\n","Names of documents retrieved for query 1 using positional index: \n","Enter phrase query 2: it is good in reliable for fit\n","Number of documents retrieved for query 2 using positional index: 1\n","Names of documents retrieved for query 2 using positional index: preprocessed_file9.txt\n","Enter phrase query 3: it is a fit front poutch\n","Number of documents retrieved for query 3 using positional index: 1\n","Names of documents retrieved for query 3 using positional index: preprocessed_file9.txt\n"]}]}]}